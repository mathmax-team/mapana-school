{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1654039322697,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"gcnmB_rLi5PQ"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1654039322699,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"hhcoitSfjD2I"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from transformers import AutoTokenizer\n","from transformers import AutoModelForSequenceClassification\n","from transformers import TrainingArguments, Trainer\n","from transformers import pipeline"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1654039322699,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"JFeqqDOUjNVF"},"outputs":[],"source":["from datasets import Dataset\n","from datasets import load_metric"]},{"cell_type":"markdown","metadata":{"id":"8C4uzYRijQYE"},"source":["# Transformers Trainer Hello World\n","This notebook shows a minimal example of fine tuning a huggingface model for text classification using the Trainer class from the transformers library."]},{"cell_type":"markdown","metadata":{"id":"3CZpxFKejmA9"},"source":["## The Dataset\n","We generate a toy datast as a pandas dataframe containing the columns 'text' and 'labels' (don't forget the s). The labels must be encoded by integers, therefore we also generate mappings to translate from int to str and viceversa."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":357,"status":"ok","timestamp":1654039323046,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"xBzdtQxAjPpq","outputId":"2ff39454-a4cd-4c4a-aecc-8e5b048f4d73"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>the food was delicious</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>the steak was delicious, best I have ever had</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>the chicken lasagna was delicious</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>everything was delicious</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>the vegan options were very convenient and del...</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>the food was terrible</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>most terrible ribs I have tasted in my life</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>the high prices do not match the terrible food</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>we had to wait a long time and the food was te...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>the lack of vegan or vegetarian options is ter...</td>\n","      <td>neg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text labels\n","0                             the food was delicious    pos\n","1      the steak was delicious, best I have ever had    pos\n","2                  the chicken lasagna was delicious    pos\n","3                           everything was delicious    pos\n","4  the vegan options were very convenient and del...    pos\n","5                              the food was terrible    neg\n","6        most terrible ribs I have tasted in my life    neg\n","7     the high prices do not match the terrible food    neg\n","8  we had to wait a long time and the food was te...    neg\n","9  the lack of vegan or vegetarian options is ter...    neg"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["positives = [['the food was delicious','pos'],\n","             ['the steak was delicious, best I have ever had','pos'],\n","             ['the chicken lasagna was delicious','pos'],\n","             ['everything was delicious','pos'],\n","             ['the vegan options were very convenient and delicious','pos']]\n","negatives = [['the food was terrible','neg'],\n","             ['most terrible ribs I have tasted in my life','neg'],\n","             ['the high prices do not match the terrible food','neg'],\n","             ['we had to wait a long time and the food was terrible','neg'],\n","             ['the lack of vegan or vegetarian options is terrible','neg']]\n","all = positives + negatives\n","df = pd.DataFrame(all,columns=['text','labels'])\n","df"]},{"cell_type":"markdown","metadata":{"id":"CUHR8I2lGvIZ"},"source":["Encode the labels as integers:"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1654039323047,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"rVd1K6fIGubX"},"outputs":[],"source":["le = LabelEncoder()\n","df['labels'] = le.fit_transform(df['labels'])\n","id2label = {i : le.classes_[i] for i in range(2)}\n","label2id = {label:code for code,label in id2label.items()}"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1654039323047,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"0sBmFC5JHMV1","outputId":"ae27d707-4ed3-4fc7-c2fe-e094c7b8ab89"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>the food was delicious</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>the steak was delicious, best I have ever had</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>the chicken lasagna was delicious</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>everything was delicious</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>the vegan options were very convenient and del...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>the food was terrible</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>most terrible ribs I have tasted in my life</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>the high prices do not match the terrible food</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>we had to wait a long time and the food was te...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>the lack of vegan or vegetarian options is ter...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  labels\n","0                             the food was delicious       1\n","1      the steak was delicious, best I have ever had       1\n","2                  the chicken lasagna was delicious       1\n","3                           everything was delicious       1\n","4  the vegan options were very convenient and del...       1\n","5                              the food was terrible       0\n","6        most terrible ribs I have tasted in my life       0\n","7     the high prices do not match the terrible food       0\n","8  we had to wait a long time and the food was te...       0\n","9  the lack of vegan or vegetarian options is ter...       0"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{"id":"WF76y_aNGigF"},"source":["Split in train and test sets:"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1654039323048,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"zYzo7yMrDaiy"},"outputs":[],"source":["X = df['text']\n","y = df['labels']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=35)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1654039323048,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"m8xWQpOFISCt"},"outputs":[],"source":["train = pd.DataFrame(columns=['text','labels'])\n","test = pd.DataFrame(columns=['text','labels'])\n","train['text']=X_train\n","train['labels']=y_train\n","test['text']=X_test\n","test['labels']=y_test"]},{"cell_type":"markdown","metadata":{"id":"pevsG3zgmn2M"},"source":["# Define the tokenizer:\n","Choose a model from the huggingface hub https://huggingface.co/models?sort=downloads"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1321,"status":"ok","timestamp":1654039324358,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"1556FcrVm6MY","outputId":"a02ff08b-37e0-4e5f-e226-2d7f3cfed182"},"outputs":[],"source":["model_ckpt = 'microsoft/MiniLM-L12-H384-uncased'\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"]},{"cell_type":"markdown","metadata":{"id":"QJq-Ny_zrWeE"},"source":["# Convert to a 'datasets' library dataset and tokenize the data:\n","The trainer class is optimized to work with this type of dataset. In particular this prevents ram shortage issues."]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1654039324359,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"wCVOR0zSOntJ"},"outputs":[],"source":["train = Dataset.from_pandas(train)\n","test = Dataset.from_pandas(test)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["9910fce29aa24da08bbde7fa27985941","41a59e99734648a3897c5f7209544d86","9a184a6179f748b49abc8aea30678518","ec46ad3adc9349ac9d2295ecab1b8d8b","d20649d78229456bbc25b2061a293ee1","821b836b2b7e4c718c4b1e1062769eb6","03122277ddd84ff9aaa7818936b723d0","24a2faf329e5425cb9e05f7f3c4c2ec3","084dd9f2a20c4f1d88a3af26ffb10bec","7c377207573d41dc89776809032bb169","1ce70f7ff1e34cfeb5e48143124a9094","c995aaf9bcbd4b35accc9e41185e7909","591cc54dc70f4c6c840ecc00490371ff","f78ef511c80349c0a80f7deee9b6d012","8430893dd9ca455da12c2b62383558d3","50516e6a03944b76acb4e0226aff84c5","84ebafbc029442ce848acba3515decbe","6917af441ee046548cdb39c8cc6ac467","448f1b9b3be84cac9c81e8f234a0e852","636906c892274edfacb2ce315cc42cd3","d5f492e09065423ea7209681b1e3e9d2","729a6543cf0642baab236c448e1434f7"]},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1654039324360,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"OF9nY86IO-wk","outputId":"23bf17ce-96cd-41c4-81d4-a374466da774"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 63.65ba/s]\n","100%|██████████| 1/1 [00:00<00:00, 247.82ba/s]\n"]}],"source":["def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"], max_length=64, padding=\"max_length\", truncation=True)\n","\n","\n","train_tokenized = train.map(tokenize_function, batched=True)\n","test_tokenized = test.map(tokenize_function, batched=True)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1654039324361,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"ibW2XGDMW0Aw","outputId":"78145058-eb10-4e5b-ca85-6311cf47687d"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['text', 'labels', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n","    num_rows: 8\n","})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train_tokenized"]},{"cell_type":"markdown","metadata":{"id":"sVMqX7Vcy3R_"},"source":["# Now import the model to fine tune and training utilities:"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":859,"status":"ok","timestamp":1654039325210,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"6wddmdFrx2bM","outputId":"10c8323d-ad3d-4fa7-9c67-89b819d2a07f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: 100%|██████████| 127M/127M [00:43<00:00, 3.09MB/s] \n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForSequenceClassification.from_pretrained(model_ckpt,\n","                                                           num_labels=2,\n","                                                           id2label=id2label,\n","                                                           label2id=label2id)"]},{"cell_type":"markdown","metadata":{"id":"cYlGeG-l14eO"},"source":["### We need a compute_metrics function to pass as an argument to the trainer"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":406,"status":"ok","timestamp":1654039325613,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"aKcNiRZV14EL"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading builder script: 4.21kB [00:00, 1.58MB/s]                   \n"]}],"source":["metric = load_metric(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1654039325613,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"c5yJ4S3C1T2P","outputId":"2d3175b8-6561-4fcb-c037-78c66b318816"},"outputs":[],"source":["args = TrainingArguments(\n","    output_dir=\"nlp/transformers_model\",\n","    evaluation_strategy=\"epoch\",\n","    num_train_epochs=3,\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=train_tokenized,\n","    eval_dataset=test_tokenized,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"executionInfo":{"elapsed":10722,"status":"ok","timestamp":1654039336323,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"IQ5C35M34qmd","outputId":"c845d96a-6a65-445e-fc42-9791361bbfb0"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","/home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 8\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3\n"," 33%|███▎      | 1/3 [00:01<00:02,  1.00s/it]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2\n","  Batch size = 8\n","                                             \n"," 33%|███▎      | 1/3 [00:01<00:02,  1.00s/it]"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.6923680305480957, 'eval_accuracy': 0.5, 'eval_runtime': 0.099, 'eval_samples_per_second': 20.21, 'eval_steps_per_second': 10.105, 'epoch': 1.0}\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 2/3 [00:02<00:01,  1.02s/it]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2\n","  Batch size = 8\n","                                             \n"," 67%|██████▋   | 2/3 [00:02<00:01,  1.02s/it]"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.6917973160743713, 'eval_accuracy': 0.5, 'eval_runtime': 0.0866, 'eval_samples_per_second': 23.088, 'eval_steps_per_second': 11.544, 'epoch': 2.0}\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3/3 [00:03<00:00,  1.00it/s]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 2\n","  Batch size = 8\n","                                             \n","100%|██████████| 3/3 [00:03<00:00,  1.00it/s]\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","100%|██████████| 3/3 [00:03<00:00,  1.04s/it]"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.6914076209068298, 'eval_accuracy': 0.5, 'eval_runtime': 0.0859, 'eval_samples_per_second': 23.281, 'eval_steps_per_second': 11.64, 'epoch': 3.0}\n","{'train_runtime': 3.1093, 'train_samples_per_second': 7.719, 'train_steps_per_second': 0.965, 'train_loss': 0.6922508875528971, 'epoch': 3.0}\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["TrainOutput(global_step=3, training_loss=0.6922508875528971, metrics={'train_runtime': 3.1093, 'train_samples_per_second': 7.719, 'train_steps_per_second': 0.965, 'train_loss': 0.6922508875528971, 'epoch': 3.0})"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"ZyWr8DdFbNZ-"},"source":["# Inference:\n","Create a pipeline object, specify the task, pass the trained model path and use the same tokenizer used for training (with the same kwargs)."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"executionInfo":{"elapsed":284,"status":"error","timestamp":1654039447317,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"fOffxxjUbeg0","outputId":"6c430767-3ec9-4081-e6c3-74b1f1d9326e"},"outputs":[{"ename":"OSError","evalue":"We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like /content/drive/MyDrive/transformers/toy_model is not the path to a directory containing a config.json file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","File \u001b[0;32m~/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py:601\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=598'>599</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=599'>600</a>\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=600'>601</a>\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_path(\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=601'>602</a>\u001b[0m         config_file,\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=602'>603</a>\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=603'>604</a>\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=604'>605</a>\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=605'>606</a>\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=606'>607</a>\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=607'>608</a>\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=608'>609</a>\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=609'>610</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=611'>612</a>\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n","File \u001b[0;32m~/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py:282\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=279'>280</a>\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=280'>281</a>\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=281'>282</a>\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=282'>283</a>\u001b[0m         url_or_filename,\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=283'>284</a>\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=284'>285</a>\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=285'>286</a>\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=286'>287</a>\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=287'>288</a>\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=288'>289</a>\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=289'>290</a>\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=290'>291</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=291'>292</a>\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=292'>293</a>\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n","File \u001b[0;32m~/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py:545\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=543'>544</a>\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=544'>545</a>\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=545'>546</a>\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mConnection error, and we cannot find the requested files in the cached path.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=546'>547</a>\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m Please try again or make sure your Internet connection is on.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=547'>548</a>\u001b[0m                 )\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/utils/hub.py?line=549'>550</a>\u001b[0m \u001b[39m# From now on, etag is not None.\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[1;32m/home/sebastian/mathmax/mapana-school/nlp/transformers_fine_tuning_hello_world.ipynb Cell 26'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sebastian/mathmax/mapana-school/nlp/transformers_fine_tuning_hello_world.ipynb#ch0000025?line=0'>1</a>\u001b[0m pipe \u001b[39m=\u001b[39m pipeline(\u001b[39m'\u001b[39;49m\u001b[39mtext-classification\u001b[39;49m\u001b[39m'\u001b[39;49m,model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/content/drive/MyDrive/transformers/toy_model\u001b[39;49m\u001b[39m'\u001b[39;49m,tokenizer \u001b[39m=\u001b[39;49m tokenizer)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sebastian/mathmax/mapana-school/nlp/transformers_fine_tuning_hello_world.ipynb#ch0000025?line=2'>3</a>\u001b[0m tokenizer_kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mpadding\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mTrue\u001b[39;00m,\u001b[39m'\u001b[39m\u001b[39mtruncation\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mTrue\u001b[39;00m,\u001b[39m'\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m64\u001b[39m}\n","File \u001b[0;32m~/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/pipelines/__init__.py:541\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=538'>539</a>\u001b[0m     config \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39mfrom_pretrained(config, revision\u001b[39m=\u001b[39mrevision, _from_pipeline\u001b[39m=\u001b[39mtask, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=539'>540</a>\u001b[0m \u001b[39melif\u001b[39;00m config \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=540'>541</a>\u001b[0m     config \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39;49mfrom_pretrained(model, revision\u001b[39m=\u001b[39;49mrevision, _from_pipeline\u001b[39m=\u001b[39;49mtask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs)\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=542'>543</a>\u001b[0m model_name \u001b[39m=\u001b[39m model \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=544'>545</a>\u001b[0m \u001b[39m# Infer the framework from the model\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=545'>546</a>\u001b[0m \u001b[39m# Forced if framework already defined, inferred if it's None\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=546'>547</a>\u001b[0m \u001b[39m# Will load the correct model if possible\u001b[39;00m\n","File \u001b[0;32m~/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py:680\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py?line=677'>678</a>\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_or_path\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pretrained_model_name_or_path\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py?line=678'>679</a>\u001b[0m trust_remote_code \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtrust_remote_code\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py?line=679'>680</a>\u001b[0m config_dict, _ \u001b[39m=\u001b[39m PretrainedConfig\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py?line=680'>681</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoConfig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py?line=681'>682</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n","File \u001b[0;32m~/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py:553\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=550'>551</a>\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=551'>552</a>\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=552'>553</a>\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=554'>555</a>\u001b[0m \u001b[39m# That config file may point us toward another config file to use.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=555'>556</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mconfiguration_files\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n","File \u001b[0;32m~/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py:634\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=629'>630</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=630'>631</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThere was a specific connection error when trying to load \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=631'>632</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=632'>633</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=633'>634</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=634'>635</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWe couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt connect to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to load this model, couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find it in the cached \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=635'>636</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfiles and it looks like \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m is not the path to a directory containing a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=636'>637</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mconfiguration_file\u001b[39m}\u001b[39;00m\u001b[39m file.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCheckout your internet connection or see how to run the library in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=637'>638</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39moffline mode at \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=638'>639</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=639'>640</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=640'>641</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=641'>642</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load config for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. If you were trying to load it from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=642'>643</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, make sure you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a local directory with the same name. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=643'>644</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOtherwise, make sure \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is the correct path to a directory \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=644'>645</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcontaining a \u001b[39m\u001b[39m{\u001b[39;00mconfiguration_file\u001b[39m}\u001b[39;00m\u001b[39m file\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/sebastian/mathmax/mapana-school/nlp/venv/lib/python3.9/site-packages/transformers/configuration_utils.py?line=645'>646</a>\u001b[0m     )\n","\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like /content/drive/MyDrive/transformers/toy_model is not the path to a directory containing a config.json file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."]}],"source":["pipe = pipeline('text-classification',model='/content/drive/MyDrive/transformers/toy_model',tokenizer = tokenizer)\n","\n","tokenizer_kwargs = {'padding':True,'truncation':True,'max_length':64}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"39Ma-l0Gc19h"},"outputs":[],"source":["test_text = test['text'][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654035005326,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"uzwyqfHQ8TbH","outputId":"9ae1108f-fdf5-4d1f-890d-8f0017477f0e"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'worst ribs I have tasted in my life'"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["test_text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2053,"status":"ok","timestamp":1654013108816,"user":{"displayName":"Sebastián Vélez","userId":"16008569911162906178"},"user_tz":300},"id":"gHRJMr7bcdor","outputId":"523273fa-c603-4db5-9857-0e21fe127ebe"},"outputs":[{"data":{"text/plain":["[{'label': 'LABEL_1', 'score': 0.9832837581634521}]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["pipe(test_text,**tokenizer_kwargs)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMZQ/7J800Phtbkos8yhVC6","collapsed_sections":[],"name":"transformers_fine_tuning_hello_world.ipynb","provenance":[]},"interpreter":{"hash":"49a7c18873c1ef10726e9cae5ceeac51644ae2658720a21ef660a39b92403863"},"kernelspec":{"display_name":"venv","language":"python","name":"venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"03122277ddd84ff9aaa7818936b723d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"084dd9f2a20c4f1d88a3af26ffb10bec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ce70f7ff1e34cfeb5e48143124a9094":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24a2faf329e5425cb9e05f7f3c4c2ec3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41a59e99734648a3897c5f7209544d86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_821b836b2b7e4c718c4b1e1062769eb6","placeholder":"​","style":"IPY_MODEL_03122277ddd84ff9aaa7818936b723d0","value":"100%"}},"448f1b9b3be84cac9c81e8f234a0e852":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50516e6a03944b76acb4e0226aff84c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"591cc54dc70f4c6c840ecc00490371ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84ebafbc029442ce848acba3515decbe","placeholder":"​","style":"IPY_MODEL_6917af441ee046548cdb39c8cc6ac467","value":"100%"}},"636906c892274edfacb2ce315cc42cd3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6917af441ee046548cdb39c8cc6ac467":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"729a6543cf0642baab236c448e1434f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c377207573d41dc89776809032bb169":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"821b836b2b7e4c718c4b1e1062769eb6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8430893dd9ca455da12c2b62383558d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5f492e09065423ea7209681b1e3e9d2","placeholder":"​","style":"IPY_MODEL_729a6543cf0642baab236c448e1434f7","value":" 1/1 [00:00&lt;00:00, 11.88ba/s]"}},"84ebafbc029442ce848acba3515decbe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9910fce29aa24da08bbde7fa27985941":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_41a59e99734648a3897c5f7209544d86","IPY_MODEL_9a184a6179f748b49abc8aea30678518","IPY_MODEL_ec46ad3adc9349ac9d2295ecab1b8d8b"],"layout":"IPY_MODEL_d20649d78229456bbc25b2061a293ee1"}},"9a184a6179f748b49abc8aea30678518":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24a2faf329e5425cb9e05f7f3c4c2ec3","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_084dd9f2a20c4f1d88a3af26ffb10bec","value":1}},"c995aaf9bcbd4b35accc9e41185e7909":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_591cc54dc70f4c6c840ecc00490371ff","IPY_MODEL_f78ef511c80349c0a80f7deee9b6d012","IPY_MODEL_8430893dd9ca455da12c2b62383558d3"],"layout":"IPY_MODEL_50516e6a03944b76acb4e0226aff84c5"}},"d20649d78229456bbc25b2061a293ee1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5f492e09065423ea7209681b1e3e9d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec46ad3adc9349ac9d2295ecab1b8d8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c377207573d41dc89776809032bb169","placeholder":"​","style":"IPY_MODEL_1ce70f7ff1e34cfeb5e48143124a9094","value":" 1/1 [00:00&lt;00:00, 15.00ba/s]"}},"f78ef511c80349c0a80f7deee9b6d012":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_448f1b9b3be84cac9c81e8f234a0e852","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_636906c892274edfacb2ce315cc42cd3","value":1}}}}},"nbformat":4,"nbformat_minor":0}
